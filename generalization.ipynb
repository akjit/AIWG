{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Limits of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "One core problem of contemporary machine learning techniques, as pointed out by [Marcus 2017], [Lake et. al. 2017], and many others, is a lack of symbolic reasoning skills in purely statistically trained (\"deep learning\" type) models like convolutional neural networks. While [Lake et. al. 2017] propose many possible technological fixes for this problem (for instance, the integration of a game-engine style physics model into a network), we could ask with [Agre 1995] if these fixes do not simply defer an inherently philosophical problem: the problem that, despite neural networks being general function approximators, intelligent generalization can not be modeled with general function approximation. As [Marcus 2017] writes: \n",
    "\n",
    "> The real problem lies in misunderstanding what deep learning is, and is not, good for. The technique excels at solving closed-end classification problems, in which a wide range of potential signals must be mapped onto a limited number of categories, given that there is enough data available and the test set closely resembles the training set.\n",
    "But deviations from these assumptions can cause problems; deep learning is just a statistical technique, and all statistical techniques suffer from deviation from their assumptions.\n",
    "\n",
    "In other words, \"true\" generalization would be closer to Cartesian compositionality then just a very large mapping betwen domains. Again [Marcus 2017]:\n",
    "\n",
    "> [S]ome problems cannot, given real- world limitations, be thought of as classification problems at all. Open-ended natural language understanding, for example, should not be thought of as a classifier mapping between a large finite set of sentences and large, finite set of sentences, but rather a mapping between a potentially infinite range of input sentences and an equally vast array of meanings, many never previously encountered. In a problem like that, deep learning becomes a square peg slammed into a round hole, a crude approximation when there must be a solution elsewhere.\n",
    "\n",
    "As an illustration of his argument, [Marcus 2017] proposes a toy example: generalizing from even to odd numbers:\n",
    "\n",
    "> Distilling the broad-ranging problems of language down to a simple example that I believe still has resonance now, I ran a series of experiments in which I trained three- layer perceptrons (fully connected in today’s technical parlance, with no convolution) on the identity function, $f(x) = x$, e.g, $f(12)=12$.\n",
    "\n",
    "The technical setup for the experiment is simple:\n",
    "\n",
    "> 1997-vintage networks were, to be sure, simpler than current models — they used no more than three layers (inputs nodes connected to hidden nodes connected to outputs node), and lacked Lecun’s powerful convolution technique. But they were driven by backpropagation just as today’s systems are, and just as beholden to their training data.\n",
    "\n",
    "The results are straightforward:\n",
    "\n",
    "> Every time I ran the experiment, using a wide variety of parameters, the results were the same: the network would (unless it got stuck in local minimum) correctly apply the identity function to the even numbers that it had seen before (say 2, 4, 8 and 12), and to some other even numbers (say 6 and 14) but fail on all the odds numbers, yielding, for example f(15) = 14. [...] Odd numbers were outside the training space, and the networks could not generalize identity outside that space. Adding more hidden units didn’t help, and nor did adding more hidden layers. Simple multilayer perceptrons simply couldn’t generalize outside their training space [...]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing the experiment\n",
    "\n",
    "In the following, we will reproduce the experiment described in [Marcus:2017]. The intention behind this is not so much the validation of his results but an excercise in critical technical practice ([Agre 1997]), in translating between philosophical and technical contexts. Additionally, given the availability of tools compared to 1997, we can implement some simple variations of the proposed experiment (more layers, different structures, etc.), and potentially show that the results still hold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "To be able to use mechanisms like differentiation and backpropagation we need a high-level library that abstracts these mathematical details away from us. We are using Keras, the de-facto standard for high-level prototyping for machine learning. Keras is a front-end to the Tensorflow framework, which is one of the ost widely used machine learning frameworks (for a comparison, see machine learning frameworks). Because we are operating in high-dimensional vectir space (and because Keras/Tensorflow use its datatypes), we are also using Numpy, the Python library for scientific computing. Finally, we are importing a single helper function from Scipy to split our data into train and test sets, and some helper functions to plot our activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabian/anaconda3/envs/py36-phd/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import expit as sigmoid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "These constants are the hyperparameters for our neural network. Exactly as proposed by [Marcus 2017], we are implementing the identity function $f(x) = x$ for binary integers. Our parameters are:\n",
    "\n",
    "- Our integers have `BITS` bits, so our network should learn to apply the identify function for $\\frac{2^{16}}{2}$ possible *even* integers.\n",
    "- After training we will test our network on `VAL` validation samples that are kept back.\n",
    "- Our hidden layers consist of `HIDDEN` units each.\n",
    "- We use `LAYERS` layers total.\n",
    "- We train the network for `EPOCHS` \"epochs\". One epoch is a complete \"run\" of all available training samples, i.e. a single forward and backward pass with all available samples.\n",
    "- We pass the samples to the network in batches of `BATCHES` each, this saves memory.\n",
    "- We do integrate some dropout layers to prevent overfitting (particularly important in this case).\n",
    "- Finally we \"mix in\" `MIX` odd numbers into our even numbers to find the threshold that enables the network to generalize for even and odd numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BITS = 16\n",
    "VAL = 100\n",
    "HIDDEN = 128\n",
    "LAYERS = 3\n",
    "EPOCHS = 1000\n",
    "BATCHES = 128\n",
    "DROPOUT = True\n",
    "MIX = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to approximate\n",
    "\n",
    "We define the most simple function possible, the identity function $f(x) = x$. To allow some additional experiments, we also define the bitwise-not function, $f(x)=\\sim{x}$. Note that the numpy implementation of bitwise not returns an array of truth values. To convert this into an array of 0s and 1s, we simply multiply it by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    \n",
    "    # Identity\n",
    "    return x\n",
    "    \n",
    "    # Bitwise not\n",
    "    # return  np.logical_not(x) * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training data\n",
    "\n",
    "Our training data is simple: a set of binary values, encoded as `BITS` dimensional vectors (e.g. `[0, 0, 1, 1, 1]`), provides both the input and desired output of our network. To produce this set, we create two two-dimensional arrays (`x_even` and `x_odd`) that will hold the even and odd numbers, respectively. We then fill the arrays from the bottom up, by iterating over the range of all $2^{\\text{BITS}}$ possible numbers with a step width of 2. In each step, we write the current number to the array that holds the even numbers, and the current number minus one to the array that holds the odd numbers. We randomly shuffle both arrays, and reserve a part for testing, and another (smaller) part for validation. Finally, we apply the function defined above to a copy of the array of even numbers, and use this as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 bit numbers = 65536 possible values.\n",
      "Train set: 29401 even binary vectors (20 odd mixed into total set).\n",
      "Test set: 3267 even binary vectors (20 odd mixed into total set).\n",
      "Validation set: 100 even binary vectors and 100 odd binary vectors.\n"
     ]
    }
   ],
   "source": [
    "MAX = 2**BITS # BITS bits = 2^BITS values\n",
    "\n",
    "# Make space for all even BITS-bit numbers and all odd BITS-bit numbers\n",
    "x_even = np.zeros((int(MAX/2), BITS), dtype=int)\n",
    "x_odd = np.zeros((int(MAX/2), BITS), dtype=int)\n",
    "\n",
    "# Fill from the bottom, converting to binary on the fly\n",
    "for i in range(0, MAX, 2):\n",
    "    x_even[int(i/2),:] = np.array(list(np.binary_repr(i, BITS)))\n",
    "    x_odd[int(i/2),:] = np.array(list(np.binary_repr(i+1, BITS)))\n",
    "\n",
    "# Randomly shuffle everything    \n",
    "np.random.shuffle(x_even)\n",
    "np.random.shuffle(x_odd)\n",
    "\n",
    "x_val_even = x_even[-VAL:,:] # Save last VAL random even numbers for prediction \n",
    "x_even = x_even[:-VAL,:] # (use the rest for training and testing)\n",
    "x_val_odd = x_odd[-VAL:,:] # Save last VAL random odd numbers for prediction (throw the rest away)\n",
    "\n",
    "x_even[:MIX,:] = x_odd[:MIX,:]\n",
    "# Randomly shuffle again   \n",
    "np.random.shuffle(x_even)\n",
    "\n",
    "# Apply function we would like to model\n",
    "y = f(x_even)\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_even, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(str(BITS) + ' bit numbers = ' + str(MAX) + ' possible values.')\n",
    "print(\"Train set: \" + str(len(x_train)) + ' even binary vectors (' + str(MIX) + ' odd mixed into total set).')\n",
    "print(\"Test set: \" + str(len(x_test)) + ' even binary vectors (' + str(MIX) + ' odd mixed into total set).')\n",
    "print(\"Validation set: \" + str(len(x_val_even)) + ' even binary vectors and ' + str(len(x_val_odd)) + ' odd binary vectors.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Keras conveniently provides us with abstractions for many of the most commonly used building blocks of neural networks. For this experiment, we are using six different components: fully connected layers, ReLu activation, a sigmoid activation, a binary cross-entropy loss function, and backporpagation by means of stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer\n",
    "\n",
    "This is the standard, multilayer perceptron layer, where every unit of a layer is connected to every unit of the layer before and after. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLu activation function\n",
    "\n",
    "[Rectified linear units](https://en.wikipedia.org/wiki/Rectifier_(neural_networks) are the most popular neural network units at the time of writing. Despite their \"linear look\", the [activation function](https://en.wikipedia.org/wiki/Activation_function) used: \n",
    "\n",
    "$$f(x)=\\max(0,x)$$\n",
    "\n",
    "is actually nonlinear ([piecewise-linear](https://en.wikipedia.org/wiki/Piecewise_linear_function), to be precise) *and* differentiable. Why nonlinear? Well, a linear function has to satisfy the condition \n",
    "\n",
    "$$\\forall_{x,y}: f(x) + f(y) = f(x+y)$$\n",
    "\n",
    "For ReLu, \n",
    "\n",
    "$$f(-1) = -1$$\n",
    "$$f(1) = 1$$\n",
    "$$f(0) = 0$$ \n",
    "\n",
    "Its derivative is then simply \n",
    "\n",
    "$$f'(x)={\\begin{cases}0&{\\text{for }}x<0\\\\1&{\\text{for }}x\\geq 0\\end{cases}}$$\n",
    "\n",
    "Interestingly, the \"almost-linearity\" of ReLus does not impede their universality in approximating functions (see [these examples](https://www.quora.com/Is-a-single-layered-ReLu-network-still-a-universal-approximator/answer/Conner-Davis-2))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7579a544a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([max(0, x) for x in np.arange(-10.0,10.0,0.1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid activation function\n",
    "\n",
    "The [sigmoid function](https://en.wikipedia.org/wiki/Logistic_function), also called logistic function, looks roughly like the simple step function but has non-zero gradients everywhere, which makes it fully differentiable. It is defined as\n",
    "\n",
    "$$f(x)={\\frac {1}{1+e^{-x}}}$$\n",
    "\n",
    "with the derivative\n",
    "\n",
    "$$f'(x)=f(x)(1-f(x))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7578ad4d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([sigmoid(x) for x in np.arange(-10.0,10.0,0.1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary cross-entopy loss function\n",
    "\n",
    "Because our input and output are binary numbers, we are dealing with a multi-label classification problem. The loss function best suited to address this scenario is binary [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy). In mathematical terms, minimizing this function equals minimizing the [Kullback–Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence), here the divergence of the probability distribution inherent in the training set and the probability distribution created by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation via stochastic gradient descent\n",
    "\n",
    "[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 37,264\n",
      "Trainable params: 37,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Dense(HIDDEN) is a fully-connected layer with HIDDEN hidden units.\n",
    "# In the first layer, you must specify the expected input data shape, here BITS-dimensional vectors.\n",
    "model.add(layers.Dense(HIDDEN, activation='relu', input_dim=BITS))\n",
    "for _ in range(LAYERS-1):\n",
    "    model.add(layers.Dense(HIDDEN, activation='relu'))\n",
    "    if (DROPOUT): model.add(layers.Dropout(0.5))\n",
    "# Sigmoid activation for multilabel classification\n",
    "# https://github.com/keras-team/keras/issues/741\n",
    "# https://en.wikipedia.org/wiki/Multi-label_classification\n",
    "model.add(layers.Dense(BITS, activation='sigmoid'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# Binary crossentropy for multilabel classification\n",
    "# https://github.com/keras-team/keras/issues/741\n",
    "# https://en.wikipedia.org/wiki/Multi-label_classification\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/1000\n",
      "29401/29401 [==============================] - 1s 44us/step - loss: 0.6590 - acc: 0.5837\n",
      "Epoch 2/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.6022 - acc: 0.6648\n",
      "Epoch 3/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.5444 - acc: 0.7247\n",
      "Epoch 4/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.4895 - acc: 0.7657\n",
      "Epoch 5/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.4422 - acc: 0.7946\n",
      "Epoch 6/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.4029 - acc: 0.8169\n",
      "Epoch 7/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.3733 - acc: 0.8332\n",
      "Epoch 8/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.3478 - acc: 0.8465\n",
      "Epoch 9/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.3280 - acc: 0.8557\n",
      "Epoch 10/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.3149 - acc: 0.8624\n",
      "Epoch 11/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.3043 - acc: 0.8670\n",
      "Epoch 12/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.2964 - acc: 0.8711\n",
      "Epoch 13/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2888 - acc: 0.8749\n",
      "Epoch 14/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2805 - acc: 0.8782\n",
      "Epoch 15/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2759 - acc: 0.8809\n",
      "Epoch 16/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2706 - acc: 0.8836\n",
      "Epoch 17/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2667 - acc: 0.8854\n",
      "Epoch 18/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2613 - acc: 0.8883\n",
      "Epoch 19/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2587 - acc: 0.8895\n",
      "Epoch 20/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2543 - acc: 0.8914\n",
      "Epoch 21/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2505 - acc: 0.8936\n",
      "Epoch 22/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2469 - acc: 0.8952\n",
      "Epoch 23/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2423 - acc: 0.8971\n",
      "Epoch 24/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2377 - acc: 0.8994\n",
      "Epoch 25/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2359 - acc: 0.9001\n",
      "Epoch 26/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.2354 - acc: 0.9008\n",
      "Epoch 27/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.2304 - acc: 0.9030\n",
      "Epoch 28/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2288 - acc: 0.9034\n",
      "Epoch 29/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2263 - acc: 0.9050\n",
      "Epoch 30/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2261 - acc: 0.9047\n",
      "Epoch 31/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2221 - acc: 0.9068\n",
      "Epoch 32/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2219 - acc: 0.9068\n",
      "Epoch 33/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2204 - acc: 0.9075\n",
      "Epoch 34/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2195 - acc: 0.9081\n",
      "Epoch 35/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2167 - acc: 0.9087\n",
      "Epoch 36/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2161 - acc: 0.9092\n",
      "Epoch 37/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2147 - acc: 0.9107\n",
      "Epoch 38/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2136 - acc: 0.9107\n",
      "Epoch 39/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2116 - acc: 0.9114\n",
      "Epoch 40/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2110 - acc: 0.9121\n",
      "Epoch 41/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2084 - acc: 0.9130\n",
      "Epoch 42/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2065 - acc: 0.9140\n",
      "Epoch 43/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2057 - acc: 0.9140\n",
      "Epoch 44/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2057 - acc: 0.9143\n",
      "Epoch 45/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2050 - acc: 0.9147\n",
      "Epoch 46/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2019 - acc: 0.9156\n",
      "Epoch 47/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.2014 - acc: 0.9163\n",
      "Epoch 48/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1998 - acc: 0.9172\n",
      "Epoch 49/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1992 - acc: 0.9173\n",
      "Epoch 50/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1980 - acc: 0.9179\n",
      "Epoch 51/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1962 - acc: 0.9193\n",
      "Epoch 52/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1961 - acc: 0.9189\n",
      "Epoch 53/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1926 - acc: 0.9207\n",
      "Epoch 54/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.1937 - acc: 0.9197\n",
      "Epoch 55/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1920 - acc: 0.9207\n",
      "Epoch 56/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1918 - acc: 0.9213\n",
      "Epoch 57/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1900 - acc: 0.9215\n",
      "Epoch 58/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1894 - acc: 0.9221\n",
      "Epoch 59/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.1880 - acc: 0.9226\n",
      "Epoch 60/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1875 - acc: 0.9229\n",
      "Epoch 61/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1851 - acc: 0.9237\n",
      "Epoch 62/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1842 - acc: 0.9242\n",
      "Epoch 63/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1838 - acc: 0.9246\n",
      "Epoch 64/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1833 - acc: 0.9247\n",
      "Epoch 65/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1810 - acc: 0.9259\n",
      "Epoch 66/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1811 - acc: 0.9256\n",
      "Epoch 67/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1796 - acc: 0.9261\n",
      "Epoch 68/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1793 - acc: 0.9265\n",
      "Epoch 69/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1775 - acc: 0.9275\n",
      "Epoch 70/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1765 - acc: 0.9278\n",
      "Epoch 71/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1757 - acc: 0.9281\n",
      "Epoch 72/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1754 - acc: 0.9287\n",
      "Epoch 73/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1718 - acc: 0.9300\n",
      "Epoch 74/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1735 - acc: 0.9294\n",
      "Epoch 75/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1717 - acc: 0.9305\n",
      "Epoch 76/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1715 - acc: 0.9299\n",
      "Epoch 77/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1691 - acc: 0.9316\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1681 - acc: 0.9317\n",
      "Epoch 79/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1678 - acc: 0.9319\n",
      "Epoch 80/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1671 - acc: 0.9323\n",
      "Epoch 81/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1656 - acc: 0.9330\n",
      "Epoch 82/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1643 - acc: 0.9340\n",
      "Epoch 83/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1641 - acc: 0.9337\n",
      "Epoch 84/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1634 - acc: 0.9338\n",
      "Epoch 85/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1621 - acc: 0.9348\n",
      "Epoch 86/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1619 - acc: 0.9355\n",
      "Epoch 87/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1602 - acc: 0.9357\n",
      "Epoch 88/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1611 - acc: 0.9353\n",
      "Epoch 89/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1587 - acc: 0.9362\n",
      "Epoch 90/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1581 - acc: 0.9370\n",
      "Epoch 91/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.1565 - acc: 0.9378\n",
      "Epoch 92/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.1568 - acc: 0.9377\n",
      "Epoch 93/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1545 - acc: 0.9387\n",
      "Epoch 94/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1552 - acc: 0.9385\n",
      "Epoch 95/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1548 - acc: 0.9383\n",
      "Epoch 96/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1528 - acc: 0.9391\n",
      "Epoch 97/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1516 - acc: 0.9401\n",
      "Epoch 98/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1513 - acc: 0.9400\n",
      "Epoch 99/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1508 - acc: 0.9402\n",
      "Epoch 100/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1498 - acc: 0.9408\n",
      "Epoch 101/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1498 - acc: 0.9409\n",
      "Epoch 102/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1496 - acc: 0.9414\n",
      "Epoch 103/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1478 - acc: 0.9421\n",
      "Epoch 104/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1476 - acc: 0.9421\n",
      "Epoch 105/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1458 - acc: 0.9429\n",
      "Epoch 106/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1476 - acc: 0.9421\n",
      "Epoch 107/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1455 - acc: 0.9431\n",
      "Epoch 108/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1450 - acc: 0.9430\n",
      "Epoch 109/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1452 - acc: 0.9429\n",
      "Epoch 110/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1445 - acc: 0.9433\n",
      "Epoch 111/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1439 - acc: 0.9436\n",
      "Epoch 112/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1423 - acc: 0.9442\n",
      "Epoch 113/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1412 - acc: 0.9448\n",
      "Epoch 114/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1410 - acc: 0.9451\n",
      "Epoch 115/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.1407 - acc: 0.9454\n",
      "Epoch 116/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1414 - acc: 0.9446\n",
      "Epoch 117/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1400 - acc: 0.9458\n",
      "Epoch 118/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1385 - acc: 0.9463\n",
      "Epoch 119/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1385 - acc: 0.9465\n",
      "Epoch 120/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1372 - acc: 0.9470\n",
      "Epoch 121/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1386 - acc: 0.9462\n",
      "Epoch 122/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1372 - acc: 0.9470\n",
      "Epoch 123/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1375 - acc: 0.9468\n",
      "Epoch 124/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.1377 - acc: 0.9469\n",
      "Epoch 125/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1364 - acc: 0.9474\n",
      "Epoch 126/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1353 - acc: 0.9474\n",
      "Epoch 127/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1349 - acc: 0.9478\n",
      "Epoch 128/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1355 - acc: 0.9476\n",
      "Epoch 129/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1340 - acc: 0.9482\n",
      "Epoch 130/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1336 - acc: 0.9486\n",
      "Epoch 131/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1321 - acc: 0.9492\n",
      "Epoch 132/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1332 - acc: 0.9485\n",
      "Epoch 133/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1316 - acc: 0.9495\n",
      "Epoch 134/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1322 - acc: 0.9491\n",
      "Epoch 135/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1319 - acc: 0.9490\n",
      "Epoch 136/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1312 - acc: 0.9497\n",
      "Epoch 137/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1312 - acc: 0.9496\n",
      "Epoch 138/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1312 - acc: 0.9498\n",
      "Epoch 139/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1304 - acc: 0.9503\n",
      "Epoch 140/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1299 - acc: 0.9501\n",
      "Epoch 141/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1301 - acc: 0.9500\n",
      "Epoch 142/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1308 - acc: 0.9501\n",
      "Epoch 143/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1285 - acc: 0.9513\n",
      "Epoch 144/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1294 - acc: 0.9506\n",
      "Epoch 145/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1271 - acc: 0.9514\n",
      "Epoch 146/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1288 - acc: 0.9511\n",
      "Epoch 147/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1273 - acc: 0.9514\n",
      "Epoch 148/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1265 - acc: 0.9518\n",
      "Epoch 149/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1261 - acc: 0.9518\n",
      "Epoch 150/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1257 - acc: 0.9523\n",
      "Epoch 151/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1261 - acc: 0.9521\n",
      "Epoch 152/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1255 - acc: 0.9528\n",
      "Epoch 153/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1252 - acc: 0.9526\n",
      "Epoch 154/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1231 - acc: 0.9533\n",
      "Epoch 155/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1232 - acc: 0.9532\n",
      "Epoch 156/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.1229 - acc: 0.9534\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.1232 - acc: 0.9533\n",
      "Epoch 158/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1233 - acc: 0.9533\n",
      "Epoch 159/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1239 - acc: 0.9530\n",
      "Epoch 160/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1226 - acc: 0.9536\n",
      "Epoch 161/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1221 - acc: 0.9538\n",
      "Epoch 162/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1217 - acc: 0.9542\n",
      "Epoch 163/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1212 - acc: 0.9540\n",
      "Epoch 164/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1212 - acc: 0.9544\n",
      "Epoch 165/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1211 - acc: 0.9543\n",
      "Epoch 166/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1205 - acc: 0.9544\n",
      "Epoch 167/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1208 - acc: 0.9544\n",
      "Epoch 168/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1181 - acc: 0.9560\n",
      "Epoch 169/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1180 - acc: 0.9558\n",
      "Epoch 170/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1183 - acc: 0.9557\n",
      "Epoch 171/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1179 - acc: 0.9559\n",
      "Epoch 172/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1170 - acc: 0.9560\n",
      "Epoch 173/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1167 - acc: 0.9560\n",
      "Epoch 174/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1162 - acc: 0.9569\n",
      "Epoch 175/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1167 - acc: 0.9561\n",
      "Epoch 176/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1167 - acc: 0.9564\n",
      "Epoch 177/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1145 - acc: 0.9577\n",
      "Epoch 178/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1150 - acc: 0.9572\n",
      "Epoch 179/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1150 - acc: 0.9570\n",
      "Epoch 180/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1131 - acc: 0.9578\n",
      "Epoch 181/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1131 - acc: 0.9580\n",
      "Epoch 182/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1134 - acc: 0.9580\n",
      "Epoch 183/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1125 - acc: 0.9581\n",
      "Epoch 184/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1125 - acc: 0.9583\n",
      "Epoch 185/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1119 - acc: 0.9583\n",
      "Epoch 186/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1124 - acc: 0.9581\n",
      "Epoch 187/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1111 - acc: 0.9588\n",
      "Epoch 188/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.1102 - acc: 0.9596\n",
      "Epoch 189/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.1112 - acc: 0.9589\n",
      "Epoch 190/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1109 - acc: 0.9591\n",
      "Epoch 191/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1096 - acc: 0.9597\n",
      "Epoch 192/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1091 - acc: 0.9596\n",
      "Epoch 193/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1093 - acc: 0.9597\n",
      "Epoch 194/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1072 - acc: 0.9609\n",
      "Epoch 195/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1088 - acc: 0.9598\n",
      "Epoch 196/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1081 - acc: 0.9602\n",
      "Epoch 197/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1075 - acc: 0.9603\n",
      "Epoch 198/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1077 - acc: 0.9600\n",
      "Epoch 199/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1073 - acc: 0.9605\n",
      "Epoch 200/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1060 - acc: 0.9608\n",
      "Epoch 201/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1064 - acc: 0.9607\n",
      "Epoch 202/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1056 - acc: 0.9611\n",
      "Epoch 203/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1050 - acc: 0.9616\n",
      "Epoch 204/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1058 - acc: 0.9611\n",
      "Epoch 205/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1045 - acc: 0.9616\n",
      "Epoch 206/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1042 - acc: 0.9615\n",
      "Epoch 207/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1053 - acc: 0.9614\n",
      "Epoch 208/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1036 - acc: 0.9620\n",
      "Epoch 209/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1035 - acc: 0.9623\n",
      "Epoch 210/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1020 - acc: 0.9627\n",
      "Epoch 211/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1017 - acc: 0.9629\n",
      "Epoch 212/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1016 - acc: 0.9627\n",
      "Epoch 213/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0995 - acc: 0.9639\n",
      "Epoch 214/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1001 - acc: 0.9638\n",
      "Epoch 215/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1007 - acc: 0.9632\n",
      "Epoch 216/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1009 - acc: 0.9631\n",
      "Epoch 217/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0999 - acc: 0.9639\n",
      "Epoch 218/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.1003 - acc: 0.9633\n",
      "Epoch 219/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0994 - acc: 0.9641\n",
      "Epoch 220/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0982 - acc: 0.9644\n",
      "Epoch 221/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0990 - acc: 0.9642\n",
      "Epoch 222/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0979 - acc: 0.9645\n",
      "Epoch 223/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0979 - acc: 0.9648\n",
      "Epoch 224/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0971 - acc: 0.9645\n",
      "Epoch 225/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0966 - acc: 0.9650\n",
      "Epoch 226/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0961 - acc: 0.9650\n",
      "Epoch 227/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0962 - acc: 0.9652\n",
      "Epoch 228/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0959 - acc: 0.9654\n",
      "Epoch 229/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0954 - acc: 0.9655\n",
      "Epoch 230/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0944 - acc: 0.9657\n",
      "Epoch 231/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0941 - acc: 0.9662\n",
      "Epoch 232/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0941 - acc: 0.9660\n",
      "Epoch 233/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0940 - acc: 0.9663\n",
      "Epoch 234/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0938 - acc: 0.9661\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0923 - acc: 0.9668\n",
      "Epoch 236/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0931 - acc: 0.9663\n",
      "Epoch 237/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0927 - acc: 0.9666\n",
      "Epoch 238/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0933 - acc: 0.9667\n",
      "Epoch 239/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0937 - acc: 0.9661\n",
      "Epoch 240/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0917 - acc: 0.9670\n",
      "Epoch 241/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0923 - acc: 0.9669\n",
      "Epoch 242/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0912 - acc: 0.9674\n",
      "Epoch 243/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0915 - acc: 0.9672\n",
      "Epoch 244/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0912 - acc: 0.9674\n",
      "Epoch 245/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0902 - acc: 0.9679\n",
      "Epoch 246/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0898 - acc: 0.9678\n",
      "Epoch 247/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0904 - acc: 0.9677\n",
      "Epoch 248/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0895 - acc: 0.9677\n",
      "Epoch 249/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0899 - acc: 0.9679\n",
      "Epoch 250/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0881 - acc: 0.9686\n",
      "Epoch 251/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0881 - acc: 0.9685\n",
      "Epoch 252/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0882 - acc: 0.9685\n",
      "Epoch 253/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0877 - acc: 0.9686\n",
      "Epoch 254/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0868 - acc: 0.9693\n",
      "Epoch 255/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0871 - acc: 0.9689\n",
      "Epoch 256/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0870 - acc: 0.9690\n",
      "Epoch 257/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0877 - acc: 0.9688\n",
      "Epoch 258/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0857 - acc: 0.9696\n",
      "Epoch 259/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0845 - acc: 0.9702\n",
      "Epoch 260/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0860 - acc: 0.9695\n",
      "Epoch 261/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0862 - acc: 0.9693\n",
      "Epoch 262/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0859 - acc: 0.9696\n",
      "Epoch 263/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0849 - acc: 0.9697\n",
      "Epoch 264/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0841 - acc: 0.9703\n",
      "Epoch 265/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0839 - acc: 0.9706\n",
      "Epoch 266/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0832 - acc: 0.9706\n",
      "Epoch 267/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0838 - acc: 0.9702\n",
      "Epoch 268/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0833 - acc: 0.9704\n",
      "Epoch 269/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0833 - acc: 0.9706\n",
      "Epoch 270/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0834 - acc: 0.9707\n",
      "Epoch 271/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0821 - acc: 0.9711\n",
      "Epoch 272/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0819 - acc: 0.9711\n",
      "Epoch 273/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0806 - acc: 0.9714\n",
      "Epoch 274/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0822 - acc: 0.9712\n",
      "Epoch 275/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0814 - acc: 0.9714\n",
      "Epoch 276/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0810 - acc: 0.9716\n",
      "Epoch 277/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0804 - acc: 0.9721\n",
      "Epoch 278/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0810 - acc: 0.9716\n",
      "Epoch 279/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0799 - acc: 0.9722\n",
      "Epoch 280/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0805 - acc: 0.9719\n",
      "Epoch 281/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0797 - acc: 0.9718\n",
      "Epoch 282/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0795 - acc: 0.9722\n",
      "Epoch 283/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0804 - acc: 0.9719\n",
      "Epoch 284/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9720\n",
      "Epoch 285/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0794 - acc: 0.9723\n",
      "Epoch 286/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0791 - acc: 0.9724\n",
      "Epoch 287/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0782 - acc: 0.9729\n",
      "Epoch 288/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0784 - acc: 0.9725\n",
      "Epoch 289/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0774 - acc: 0.9730\n",
      "Epoch 290/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0781 - acc: 0.9726\n",
      "Epoch 291/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0769 - acc: 0.9735\n",
      "Epoch 292/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0772 - acc: 0.9733\n",
      "Epoch 293/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0758 - acc: 0.9736\n",
      "Epoch 294/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0762 - acc: 0.9738\n",
      "Epoch 295/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0749 - acc: 0.9741\n",
      "Epoch 296/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0759 - acc: 0.9741\n",
      "Epoch 297/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0766 - acc: 0.9735\n",
      "Epoch 298/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0753 - acc: 0.9739\n",
      "Epoch 299/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0743 - acc: 0.9744\n",
      "Epoch 300/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0759 - acc: 0.9739\n",
      "Epoch 301/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0743 - acc: 0.9747\n",
      "Epoch 302/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0750 - acc: 0.9744\n",
      "Epoch 303/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0739 - acc: 0.9745\n",
      "Epoch 304/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0742 - acc: 0.9743\n",
      "Epoch 305/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0743 - acc: 0.9748\n",
      "Epoch 306/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0734 - acc: 0.9749\n",
      "Epoch 307/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0736 - acc: 0.9746\n",
      "Epoch 308/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0725 - acc: 0.9753\n",
      "Epoch 309/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0728 - acc: 0.9754\n",
      "Epoch 310/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0733 - acc: 0.9749\n",
      "Epoch 311/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0720 - acc: 0.9754\n",
      "Epoch 312/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0713 - acc: 0.9757\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0722 - acc: 0.9757\n",
      "Epoch 314/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0706 - acc: 0.9763\n",
      "Epoch 315/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0716 - acc: 0.9757\n",
      "Epoch 316/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0717 - acc: 0.9756\n",
      "Epoch 317/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0716 - acc: 0.9757\n",
      "Epoch 318/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0698 - acc: 0.9764\n",
      "Epoch 319/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0710 - acc: 0.9759\n",
      "Epoch 320/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0700 - acc: 0.9766\n",
      "Epoch 321/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0702 - acc: 0.9761\n",
      "Epoch 322/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0701 - acc: 0.9765\n",
      "Epoch 323/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0703 - acc: 0.9764\n",
      "Epoch 324/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0691 - acc: 0.9766\n",
      "Epoch 325/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0692 - acc: 0.9767\n",
      "Epoch 326/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0700 - acc: 0.9768\n",
      "Epoch 327/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0690 - acc: 0.9768\n",
      "Epoch 328/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0687 - acc: 0.9770\n",
      "Epoch 329/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0684 - acc: 0.9772\n",
      "Epoch 330/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0684 - acc: 0.9773\n",
      "Epoch 331/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0680 - acc: 0.9772\n",
      "Epoch 332/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0676 - acc: 0.9776\n",
      "Epoch 333/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0682 - acc: 0.9774\n",
      "Epoch 334/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0675 - acc: 0.9776\n",
      "Epoch 335/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0671 - acc: 0.9777\n",
      "Epoch 336/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0659 - acc: 0.9781\n",
      "Epoch 337/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0662 - acc: 0.9779\n",
      "Epoch 338/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0662 - acc: 0.9780\n",
      "Epoch 339/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0660 - acc: 0.9782\n",
      "Epoch 340/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0659 - acc: 0.9781\n",
      "Epoch 341/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0666 - acc: 0.9779\n",
      "Epoch 342/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0663 - acc: 0.9781\n",
      "Epoch 343/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0658 - acc: 0.9782\n",
      "Epoch 344/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0664 - acc: 0.9780\n",
      "Epoch 345/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0645 - acc: 0.9786\n",
      "Epoch 346/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0649 - acc: 0.9787\n",
      "Epoch 347/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0652 - acc: 0.9784\n",
      "Epoch 348/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0649 - acc: 0.9789\n",
      "Epoch 349/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0648 - acc: 0.9787\n",
      "Epoch 350/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0642 - acc: 0.9790\n",
      "Epoch 351/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0645 - acc: 0.9790\n",
      "Epoch 352/1000\n",
      "29401/29401 [==============================] - 0s 16us/step - loss: 0.0648 - acc: 0.9788\n",
      "Epoch 353/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0637 - acc: 0.9792\n",
      "Epoch 354/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0639 - acc: 0.9793\n",
      "Epoch 355/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0636 - acc: 0.9793\n",
      "Epoch 356/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0632 - acc: 0.9795\n",
      "Epoch 357/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0629 - acc: 0.9797\n",
      "Epoch 358/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0638 - acc: 0.9792\n",
      "Epoch 359/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0631 - acc: 0.9793\n",
      "Epoch 360/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0629 - acc: 0.9796\n",
      "Epoch 361/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0625 - acc: 0.9798\n",
      "Epoch 362/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0627 - acc: 0.9798\n",
      "Epoch 363/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0622 - acc: 0.9799\n",
      "Epoch 364/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0622 - acc: 0.9799\n",
      "Epoch 365/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0619 - acc: 0.9802\n",
      "Epoch 366/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0630 - acc: 0.9797\n",
      "Epoch 367/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0617 - acc: 0.9802\n",
      "Epoch 368/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0608 - acc: 0.9804\n",
      "Epoch 369/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0612 - acc: 0.9804\n",
      "Epoch 370/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0617 - acc: 0.9803\n",
      "Epoch 371/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0603 - acc: 0.9806\n",
      "Epoch 372/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0608 - acc: 0.9807\n",
      "Epoch 373/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0603 - acc: 0.9807\n",
      "Epoch 374/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0607 - acc: 0.9809\n",
      "Epoch 375/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0606 - acc: 0.9808\n",
      "Epoch 376/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0606 - acc: 0.9808\n",
      "Epoch 377/1000\n",
      "29401/29401 [==============================] - 0s 16us/step - loss: 0.0598 - acc: 0.9810\n",
      "Epoch 378/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0598 - acc: 0.9809\n",
      "Epoch 379/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0597 - acc: 0.9812\n",
      "Epoch 380/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0596 - acc: 0.9813\n",
      "Epoch 381/1000\n",
      "29401/29401 [==============================] - 1s 18us/step - loss: 0.0600 - acc: 0.9812\n",
      "Epoch 382/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0598 - acc: 0.9810\n",
      "Epoch 383/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0592 - acc: 0.9811\n",
      "Epoch 384/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0589 - acc: 0.9815\n",
      "Epoch 385/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0589 - acc: 0.9814\n",
      "Epoch 386/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0594 - acc: 0.9812\n",
      "Epoch 387/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0588 - acc: 0.9813\n",
      "Epoch 388/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0580 - acc: 0.9817\n",
      "Epoch 389/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0582 - acc: 0.9818\n",
      "Epoch 390/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0587 - acc: 0.9815\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0577 - acc: 0.9820\n",
      "Epoch 392/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0582 - acc: 0.9816\n",
      "Epoch 393/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0579 - acc: 0.9821\n",
      "Epoch 394/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0579 - acc: 0.9819\n",
      "Epoch 395/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0577 - acc: 0.9820\n",
      "Epoch 396/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0568 - acc: 0.9822\n",
      "Epoch 397/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0571 - acc: 0.9823\n",
      "Epoch 398/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0562 - acc: 0.9825\n",
      "Epoch 399/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0564 - acc: 0.9826\n",
      "Epoch 400/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0572 - acc: 0.9822\n",
      "Epoch 401/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0565 - acc: 0.9825\n",
      "Epoch 402/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0564 - acc: 0.9824\n",
      "Epoch 403/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0568 - acc: 0.9825\n",
      "Epoch 404/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0563 - acc: 0.9828\n",
      "Epoch 405/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0559 - acc: 0.9828\n",
      "Epoch 406/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0553 - acc: 0.9829\n",
      "Epoch 407/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0567 - acc: 0.9826\n",
      "Epoch 408/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0554 - acc: 0.9828\n",
      "Epoch 409/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9830\n",
      "Epoch 410/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0564 - acc: 0.9825\n",
      "Epoch 411/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0554 - acc: 0.9830\n",
      "Epoch 412/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0558 - acc: 0.9829\n",
      "Epoch 413/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0556 - acc: 0.9829\n",
      "Epoch 414/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0551 - acc: 0.9832\n",
      "Epoch 415/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0544 - acc: 0.9833\n",
      "Epoch 416/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0546 - acc: 0.9834\n",
      "Epoch 417/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0556 - acc: 0.9829\n",
      "Epoch 418/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0552 - acc: 0.9828\n",
      "Epoch 419/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0548 - acc: 0.9835\n",
      "Epoch 420/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0544 - acc: 0.9833\n",
      "Epoch 421/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0541 - acc: 0.9835\n",
      "Epoch 422/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0538 - acc: 0.9837\n",
      "Epoch 423/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0544 - acc: 0.9834\n",
      "Epoch 424/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0537 - acc: 0.9838\n",
      "Epoch 425/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0534 - acc: 0.9838\n",
      "Epoch 426/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0533 - acc: 0.9839\n",
      "Epoch 427/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0527 - acc: 0.9839\n",
      "Epoch 428/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0534 - acc: 0.9838\n",
      "Epoch 429/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0530 - acc: 0.9840\n",
      "Epoch 430/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0528 - acc: 0.9842\n",
      "Epoch 431/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0531 - acc: 0.9838\n",
      "Epoch 432/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0529 - acc: 0.9839\n",
      "Epoch 433/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0522 - acc: 0.9842\n",
      "Epoch 434/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0521 - acc: 0.9844\n",
      "Epoch 435/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0523 - acc: 0.9841\n",
      "Epoch 436/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0527 - acc: 0.9841\n",
      "Epoch 437/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0525 - acc: 0.9843\n",
      "Epoch 438/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0523 - acc: 0.9842\n",
      "Epoch 439/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0527 - acc: 0.9841\n",
      "Epoch 440/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0511 - acc: 0.9845\n",
      "Epoch 441/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0522 - acc: 0.9842\n",
      "Epoch 442/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0519 - acc: 0.9844\n",
      "Epoch 443/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0519 - acc: 0.9843\n",
      "Epoch 444/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0522 - acc: 0.9843\n",
      "Epoch 445/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0516 - acc: 0.9845\n",
      "Epoch 446/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0515 - acc: 0.9846\n",
      "Epoch 447/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0517 - acc: 0.9845\n",
      "Epoch 448/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0515 - acc: 0.9846\n",
      "Epoch 449/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0506 - acc: 0.9848\n",
      "Epoch 450/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0511 - acc: 0.9847\n",
      "Epoch 451/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0510 - acc: 0.9846\n",
      "Epoch 452/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0511 - acc: 0.9847\n",
      "Epoch 453/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0508 - acc: 0.9849\n",
      "Epoch 454/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0502 - acc: 0.9850\n",
      "Epoch 455/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0507 - acc: 0.9851\n",
      "Epoch 456/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0511 - acc: 0.9849\n",
      "Epoch 457/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0511 - acc: 0.9847\n",
      "Epoch 458/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0506 - acc: 0.9848\n",
      "Epoch 459/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0497 - acc: 0.9852\n",
      "Epoch 460/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0505 - acc: 0.9850\n",
      "Epoch 461/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0509 - acc: 0.9846\n",
      "Epoch 462/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0495 - acc: 0.9852\n",
      "Epoch 463/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0502 - acc: 0.9851\n",
      "Epoch 464/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0494 - acc: 0.9852\n",
      "Epoch 465/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0492 - acc: 0.9855\n",
      "Epoch 466/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0501 - acc: 0.9850\n",
      "Epoch 467/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0496 - acc: 0.9853\n",
      "Epoch 468/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0498 - acc: 0.9852\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0497 - acc: 0.9855\n",
      "Epoch 470/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0495 - acc: 0.9851\n",
      "Epoch 471/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0494 - acc: 0.9853\n",
      "Epoch 472/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0491 - acc: 0.9854\n",
      "Epoch 473/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0495 - acc: 0.9852\n",
      "Epoch 474/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0491 - acc: 0.9854\n",
      "Epoch 475/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0482 - acc: 0.9858\n",
      "Epoch 476/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0492 - acc: 0.9853\n",
      "Epoch 477/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0483 - acc: 0.9856\n",
      "Epoch 478/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0496 - acc: 0.9851\n",
      "Epoch 479/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0490 - acc: 0.9855\n",
      "Epoch 480/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0485 - acc: 0.9857\n",
      "Epoch 481/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0484 - acc: 0.9855\n",
      "Epoch 482/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0486 - acc: 0.9856\n",
      "Epoch 483/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0481 - acc: 0.9860\n",
      "Epoch 484/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0478 - acc: 0.9858\n",
      "Epoch 485/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0485 - acc: 0.9857\n",
      "Epoch 486/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0475 - acc: 0.9860\n",
      "Epoch 487/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0474 - acc: 0.9861\n",
      "Epoch 488/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0480 - acc: 0.9860\n",
      "Epoch 489/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0475 - acc: 0.9860\n",
      "Epoch 490/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0484 - acc: 0.9857\n",
      "Epoch 491/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0489 - acc: 0.9855\n",
      "Epoch 492/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0474 - acc: 0.9861\n",
      "Epoch 493/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0469 - acc: 0.9861\n",
      "Epoch 494/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0477 - acc: 0.9860\n",
      "Epoch 495/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0473 - acc: 0.9859\n",
      "Epoch 496/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0472 - acc: 0.9861\n",
      "Epoch 497/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0474 - acc: 0.9861\n",
      "Epoch 498/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0480 - acc: 0.9860\n",
      "Epoch 499/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0472 - acc: 0.9861\n",
      "Epoch 500/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0472 - acc: 0.9862\n",
      "Epoch 501/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0471 - acc: 0.9861\n",
      "Epoch 502/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0474 - acc: 0.9861\n",
      "Epoch 503/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0472 - acc: 0.9864\n",
      "Epoch 504/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0475 - acc: 0.9862\n",
      "Epoch 505/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0464 - acc: 0.9864\n",
      "Epoch 506/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9862\n",
      "Epoch 507/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0463 - acc: 0.9864\n",
      "Epoch 508/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0469 - acc: 0.9862\n",
      "Epoch 509/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0466 - acc: 0.9864\n",
      "Epoch 510/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0466 - acc: 0.9864\n",
      "Epoch 511/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0468 - acc: 0.9863\n",
      "Epoch 512/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0467 - acc: 0.9864\n",
      "Epoch 513/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0462 - acc: 0.9866\n",
      "Epoch 514/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0464 - acc: 0.9865\n",
      "Epoch 515/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0460 - acc: 0.9865\n",
      "Epoch 516/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0459 - acc: 0.9866\n",
      "Epoch 517/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0464 - acc: 0.9865\n",
      "Epoch 518/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0467 - acc: 0.9864\n",
      "Epoch 519/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0459 - acc: 0.9867\n",
      "Epoch 520/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0460 - acc: 0.9866\n",
      "Epoch 521/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0459 - acc: 0.9867\n",
      "Epoch 522/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0460 - acc: 0.9866\n",
      "Epoch 523/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0466 - acc: 0.9865\n",
      "Epoch 524/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0460 - acc: 0.9866\n",
      "Epoch 525/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0459 - acc: 0.9866\n",
      "Epoch 526/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0456 - acc: 0.9868\n",
      "Epoch 527/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0462 - acc: 0.9866\n",
      "Epoch 528/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0457 - acc: 0.9868\n",
      "Epoch 529/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0464 - acc: 0.9865\n",
      "Epoch 530/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0453 - acc: 0.9867\n",
      "Epoch 531/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0455 - acc: 0.9868\n",
      "Epoch 532/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0463 - acc: 0.9864\n",
      "Epoch 533/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0453 - acc: 0.9868\n",
      "Epoch 534/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0457 - acc: 0.9868\n",
      "Epoch 535/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0448 - acc: 0.9872\n",
      "Epoch 536/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0443 - acc: 0.9871\n",
      "Epoch 537/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0452 - acc: 0.9867\n",
      "Epoch 538/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0454 - acc: 0.9869\n",
      "Epoch 539/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0457 - acc: 0.9867\n",
      "Epoch 540/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0444 - acc: 0.9872\n",
      "Epoch 541/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0450 - acc: 0.9870\n",
      "Epoch 542/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0452 - acc: 0.9869\n",
      "Epoch 543/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0457 - acc: 0.9869\n",
      "Epoch 544/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0445 - acc: 0.9872\n",
      "Epoch 545/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0455 - acc: 0.9870\n",
      "Epoch 546/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0455 - acc: 0.9869\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0448 - acc: 0.9869\n",
      "Epoch 548/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0452 - acc: 0.9869\n",
      "Epoch 549/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0454 - acc: 0.9869\n",
      "Epoch 550/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0445 - acc: 0.9872\n",
      "Epoch 551/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0452 - acc: 0.9869\n",
      "Epoch 552/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0438 - acc: 0.9874\n",
      "Epoch 553/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0449 - acc: 0.9870\n",
      "Epoch 554/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0445 - acc: 0.9872\n",
      "Epoch 555/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0442 - acc: 0.9872\n",
      "Epoch 556/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0443 - acc: 0.9872\n",
      "Epoch 557/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0447 - acc: 0.9872\n",
      "Epoch 558/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0437 - acc: 0.9873\n",
      "Epoch 559/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0450 - acc: 0.9871\n",
      "Epoch 560/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0445 - acc: 0.9870\n",
      "Epoch 561/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0436 - acc: 0.9873\n",
      "Epoch 562/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0452 - acc: 0.9868\n",
      "Epoch 563/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0441 - acc: 0.9873\n",
      "Epoch 564/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0444 - acc: 0.9872\n",
      "Epoch 565/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0443 - acc: 0.9872\n",
      "Epoch 566/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0437 - acc: 0.9874\n",
      "Epoch 567/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0435 - acc: 0.9875\n",
      "Epoch 568/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0440 - acc: 0.9873\n",
      "Epoch 569/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0437 - acc: 0.9874\n",
      "Epoch 570/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0432 - acc: 0.9875\n",
      "Epoch 571/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0437 - acc: 0.9875\n",
      "Epoch 572/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0441 - acc: 0.9873\n",
      "Epoch 573/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0436 - acc: 0.9875\n",
      "Epoch 574/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0443 - acc: 0.9872\n",
      "Epoch 575/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0441 - acc: 0.9872\n",
      "Epoch 576/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0438 - acc: 0.9874\n",
      "Epoch 577/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0435 - acc: 0.9875\n",
      "Epoch 578/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0449 - acc: 0.9869\n",
      "Epoch 579/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0437 - acc: 0.9874\n",
      "Epoch 580/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0436 - acc: 0.9875\n",
      "Epoch 581/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0439 - acc: 0.9874\n",
      "Epoch 582/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0428 - acc: 0.9878\n",
      "Epoch 583/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0430 - acc: 0.9877\n",
      "Epoch 584/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0430 - acc: 0.9877\n",
      "Epoch 585/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0435 - acc: 0.9874\n",
      "Epoch 586/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0433 - acc: 0.9875\n",
      "Epoch 587/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0437 - acc: 0.9875\n",
      "Epoch 588/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0438 - acc: 0.9873\n",
      "Epoch 589/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0437 - acc: 0.9876\n",
      "Epoch 590/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0428 - acc: 0.9878\n",
      "Epoch 591/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0431 - acc: 0.9874\n",
      "Epoch 592/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0433 - acc: 0.9875\n",
      "Epoch 593/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0433 - acc: 0.9877\n",
      "Epoch 594/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0432 - acc: 0.9877\n",
      "Epoch 595/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0433 - acc: 0.9875\n",
      "Epoch 596/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0430 - acc: 0.9879\n",
      "Epoch 597/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0425 - acc: 0.9879\n",
      "Epoch 598/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0430 - acc: 0.9876\n",
      "Epoch 599/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0429 - acc: 0.9877\n",
      "Epoch 600/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0430 - acc: 0.9877\n",
      "Epoch 601/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0424 - acc: 0.9879\n",
      "Epoch 602/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0431 - acc: 0.9877\n",
      "Epoch 603/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0433 - acc: 0.9876\n",
      "Epoch 604/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0433 - acc: 0.9876\n",
      "Epoch 605/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0426 - acc: 0.9879\n",
      "Epoch 606/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0425 - acc: 0.9879\n",
      "Epoch 607/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0431 - acc: 0.9874\n",
      "Epoch 608/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0428 - acc: 0.9876\n",
      "Epoch 609/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0425 - acc: 0.9879\n",
      "Epoch 610/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0426 - acc: 0.9880\n",
      "Epoch 611/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0422 - acc: 0.9878\n",
      "Epoch 612/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0425 - acc: 0.9879\n",
      "Epoch 613/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0426 - acc: 0.9877\n",
      "Epoch 614/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0439 - acc: 0.9876\n",
      "Epoch 615/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0425 - acc: 0.9879\n",
      "Epoch 616/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0429 - acc: 0.9877\n",
      "Epoch 617/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0424 - acc: 0.9879\n",
      "Epoch 618/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0424 - acc: 0.9879\n",
      "Epoch 619/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0427 - acc: 0.9878\n",
      "Epoch 620/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0423 - acc: 0.9878\n",
      "Epoch 621/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0427 - acc: 0.9880\n",
      "Epoch 622/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0426 - acc: 0.9878\n",
      "Epoch 623/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0421 - acc: 0.9880\n",
      "Epoch 624/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0417 - acc: 0.9881\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0428 - acc: 0.9878\n",
      "Epoch 626/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0425 - acc: 0.9877\n",
      "Epoch 627/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0414 - acc: 0.9882\n",
      "Epoch 628/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0422 - acc: 0.9879\n",
      "Epoch 629/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0421 - acc: 0.9881\n",
      "Epoch 630/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0420 - acc: 0.9880\n",
      "Epoch 631/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0431 - acc: 0.9877\n",
      "Epoch 632/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0417 - acc: 0.9880\n",
      "Epoch 633/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0421 - acc: 0.9880\n",
      "Epoch 634/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0426 - acc: 0.9879\n",
      "Epoch 635/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0426 - acc: 0.9879\n",
      "Epoch 636/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0423 - acc: 0.9879\n",
      "Epoch 637/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0411 - acc: 0.9882\n",
      "Epoch 638/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0422 - acc: 0.9879\n",
      "Epoch 639/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0419 - acc: 0.9880\n",
      "Epoch 640/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0412 - acc: 0.9884\n",
      "Epoch 641/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0420 - acc: 0.9880\n",
      "Epoch 642/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0426 - acc: 0.9878\n",
      "Epoch 643/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0419 - acc: 0.9881\n",
      "Epoch 644/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0421 - acc: 0.9880\n",
      "Epoch 645/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0413 - acc: 0.9881\n",
      "Epoch 646/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0416 - acc: 0.9881\n",
      "Epoch 647/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0424 - acc: 0.9879\n",
      "Epoch 648/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9883\n",
      "Epoch 649/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0411 - acc: 0.9884\n",
      "Epoch 650/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0424 - acc: 0.9879\n",
      "Epoch 651/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0414 - acc: 0.9882\n",
      "Epoch 652/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0419 - acc: 0.9881\n",
      "Epoch 653/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0412 - acc: 0.9882\n",
      "Epoch 654/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0417 - acc: 0.9881\n",
      "Epoch 655/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0414 - acc: 0.9882\n",
      "Epoch 656/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0414 - acc: 0.9883\n",
      "Epoch 657/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0419 - acc: 0.9881\n",
      "Epoch 658/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0421 - acc: 0.9880\n",
      "Epoch 659/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0416 - acc: 0.9882\n",
      "Epoch 660/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0411 - acc: 0.9884\n",
      "Epoch 661/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0422 - acc: 0.9879\n",
      "Epoch 662/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0417 - acc: 0.9880\n",
      "Epoch 663/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0416 - acc: 0.9881\n",
      "Epoch 664/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0418 - acc: 0.9881\n",
      "Epoch 665/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9883\n",
      "Epoch 666/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0409 - acc: 0.9884\n",
      "Epoch 667/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0415 - acc: 0.9881\n",
      "Epoch 668/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0415 - acc: 0.9881\n",
      "Epoch 669/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0414 - acc: 0.9882\n",
      "Epoch 670/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0411 - acc: 0.9882\n",
      "Epoch 671/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0416 - acc: 0.9882\n",
      "Epoch 672/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0418 - acc: 0.9881\n",
      "Epoch 673/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0412 - acc: 0.9883\n",
      "Epoch 674/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0417 - acc: 0.9883\n",
      "Epoch 675/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0415 - acc: 0.9883\n",
      "Epoch 676/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0413 - acc: 0.9883\n",
      "Epoch 677/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0414 - acc: 0.9880\n",
      "Epoch 678/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9883\n",
      "Epoch 679/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0416 - acc: 0.9883\n",
      "Epoch 680/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9884\n",
      "Epoch 681/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9882\n",
      "Epoch 682/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0411 - acc: 0.9882\n",
      "Epoch 683/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9885\n",
      "Epoch 684/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0402 - acc: 0.9886\n",
      "Epoch 685/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0412 - acc: 0.9884\n",
      "Epoch 686/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0409 - acc: 0.9886\n",
      "Epoch 687/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9884\n",
      "Epoch 688/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0409 - acc: 0.9883\n",
      "Epoch 689/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0412 - acc: 0.9884\n",
      "Epoch 690/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0411 - acc: 0.9883\n",
      "Epoch 691/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0405 - acc: 0.9884\n",
      "Epoch 692/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9883\n",
      "Epoch 693/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0407 - acc: 0.9884\n",
      "Epoch 694/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0408 - acc: 0.9885\n",
      "Epoch 695/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9882\n",
      "Epoch 696/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0405 - acc: 0.9884\n",
      "Epoch 697/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0412 - acc: 0.9883\n",
      "Epoch 698/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0409 - acc: 0.9884\n",
      "Epoch 699/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0411 - acc: 0.9883\n",
      "Epoch 700/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0406 - acc: 0.9886\n",
      "Epoch 701/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0399 - acc: 0.9887\n",
      "Epoch 702/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0406 - acc: 0.9885\n",
      "Epoch 703/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0405 - acc: 0.9885\n",
      "Epoch 704/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0408 - acc: 0.9883\n",
      "Epoch 705/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0399 - acc: 0.9885\n",
      "Epoch 706/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0405 - acc: 0.9886\n",
      "Epoch 707/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0407 - acc: 0.9885\n",
      "Epoch 708/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0409 - acc: 0.9884\n",
      "Epoch 709/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0401 - acc: 0.9885\n",
      "Epoch 710/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0409 - acc: 0.9883\n",
      "Epoch 711/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0401 - acc: 0.9886\n",
      "Epoch 712/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0404 - acc: 0.9884\n",
      "Epoch 713/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0405 - acc: 0.9886\n",
      "Epoch 714/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0408 - acc: 0.9884\n",
      "Epoch 715/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0407 - acc: 0.9883\n",
      "Epoch 716/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0408 - acc: 0.9883\n",
      "Epoch 717/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0402 - acc: 0.9885\n",
      "Epoch 718/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0397 - acc: 0.9888\n",
      "Epoch 719/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0413 - acc: 0.9883\n",
      "Epoch 720/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0399 - acc: 0.9888\n",
      "Epoch 721/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0405 - acc: 0.9886\n",
      "Epoch 722/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0403 - acc: 0.9886\n",
      "Epoch 723/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0406 - acc: 0.9886\n",
      "Epoch 724/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0402 - acc: 0.9886\n",
      "Epoch 725/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0401 - acc: 0.9886\n",
      "Epoch 726/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0406 - acc: 0.9886\n",
      "Epoch 727/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0403 - acc: 0.9887\n",
      "Epoch 728/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0396 - acc: 0.9889\n",
      "Epoch 729/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0410 - acc: 0.9883\n",
      "Epoch 730/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0400 - acc: 0.9887\n",
      "Epoch 731/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0408 - acc: 0.9884\n",
      "Epoch 732/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0393 - acc: 0.9889\n",
      "Epoch 733/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0401 - acc: 0.9888\n",
      "Epoch 734/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0405 - acc: 0.9886\n",
      "Epoch 735/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0404 - acc: 0.9886\n",
      "Epoch 736/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9889\n",
      "Epoch 737/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9888\n",
      "Epoch 738/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0402 - acc: 0.9888\n",
      "Epoch 739/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0398 - acc: 0.9889\n",
      "Epoch 740/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0400 - acc: 0.9888\n",
      "Epoch 741/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0390 - acc: 0.9889\n",
      "Epoch 742/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0401 - acc: 0.9887\n",
      "Epoch 743/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0396 - acc: 0.9887\n",
      "Epoch 744/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0404 - acc: 0.9885\n",
      "Epoch 745/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0397 - acc: 0.9887\n",
      "Epoch 746/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0400 - acc: 0.9886\n",
      "Epoch 747/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0402 - acc: 0.9887\n",
      "Epoch 748/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0402 - acc: 0.9886\n",
      "Epoch 749/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0396 - acc: 0.9887\n",
      "Epoch 750/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0398 - acc: 0.9888\n",
      "Epoch 751/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0396 - acc: 0.9889\n",
      "Epoch 752/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0399 - acc: 0.9886\n",
      "Epoch 753/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0399 - acc: 0.9888\n",
      "Epoch 754/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0398 - acc: 0.9888\n",
      "Epoch 755/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0396 - acc: 0.9889\n",
      "Epoch 756/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0398 - acc: 0.9888\n",
      "Epoch 757/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0397 - acc: 0.9889\n",
      "Epoch 758/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9890\n",
      "Epoch 759/1000\n",
      "29401/29401 [==============================] - 0s 16us/step - loss: 0.0395 - acc: 0.9888\n",
      "Epoch 760/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0403 - acc: 0.9885\n",
      "Epoch 761/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0400 - acc: 0.9887\n",
      "Epoch 762/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0395 - acc: 0.9888\n",
      "Epoch 763/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0394 - acc: 0.9889\n",
      "Epoch 764/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0393 - acc: 0.9889\n",
      "Epoch 765/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0404 - acc: 0.9886\n",
      "Epoch 766/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0404 - acc: 0.9887\n",
      "Epoch 767/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0385 - acc: 0.9892\n",
      "Epoch 768/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0405 - acc: 0.9886\n",
      "Epoch 769/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0391 - acc: 0.9892\n",
      "Epoch 770/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0400 - acc: 0.9888\n",
      "Epoch 771/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0387 - acc: 0.9892\n",
      "Epoch 772/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0400 - acc: 0.9888\n",
      "Epoch 773/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0394 - acc: 0.9888\n",
      "Epoch 774/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0394 - acc: 0.9888\n",
      "Epoch 775/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0387 - acc: 0.9891\n",
      "Epoch 776/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0400 - acc: 0.9887\n",
      "Epoch 777/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0392 - acc: 0.9891\n",
      "Epoch 778/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0392 - acc: 0.9890\n",
      "Epoch 779/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0393 - acc: 0.9891\n",
      "Epoch 780/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0397 - acc: 0.9889\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0387 - acc: 0.9892\n",
      "Epoch 782/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0387 - acc: 0.9891\n",
      "Epoch 783/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0394 - acc: 0.9889\n",
      "Epoch 784/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0398 - acc: 0.9888\n",
      "Epoch 785/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0396 - acc: 0.9889\n",
      "Epoch 786/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0390 - acc: 0.9892\n",
      "Epoch 787/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0395 - acc: 0.9888\n",
      "Epoch 788/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0391 - acc: 0.9889\n",
      "Epoch 789/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0383 - acc: 0.9894\n",
      "Epoch 790/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0391 - acc: 0.9891\n",
      "Epoch 791/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0392 - acc: 0.9890\n",
      "Epoch 792/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0391 - acc: 0.9891\n",
      "Epoch 793/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0385 - acc: 0.9891\n",
      "Epoch 794/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0400 - acc: 0.9889\n",
      "Epoch 795/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0391 - acc: 0.9891\n",
      "Epoch 796/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0391 - acc: 0.9890\n",
      "Epoch 797/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0393 - acc: 0.9888\n",
      "Epoch 798/1000\n",
      "29401/29401 [==============================] - 0s 16us/step - loss: 0.0396 - acc: 0.9889\n",
      "Epoch 799/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0390 - acc: 0.9891\n",
      "Epoch 800/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0387 - acc: 0.9892\n",
      "Epoch 801/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0398 - acc: 0.9889\n",
      "Epoch 802/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0385 - acc: 0.9892\n",
      "Epoch 803/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0392 - acc: 0.9890\n",
      "Epoch 804/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0383 - acc: 0.9893\n",
      "Epoch 805/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0391 - acc: 0.9890\n",
      "Epoch 806/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0390 - acc: 0.9890\n",
      "Epoch 807/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0390 - acc: 0.9891\n",
      "Epoch 808/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0392 - acc: 0.9890\n",
      "Epoch 809/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0388 - acc: 0.9891\n",
      "Epoch 810/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0386 - acc: 0.9893\n",
      "Epoch 811/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0389 - acc: 0.9891\n",
      "Epoch 812/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9893\n",
      "Epoch 813/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0390 - acc: 0.9892\n",
      "Epoch 814/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0389 - acc: 0.9892\n",
      "Epoch 815/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0396 - acc: 0.9890\n",
      "Epoch 816/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0390 - acc: 0.9892\n",
      "Epoch 817/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0388 - acc: 0.9892\n",
      "Epoch 818/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0378 - acc: 0.9894\n",
      "Epoch 819/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0391 - acc: 0.9892\n",
      "Epoch 820/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0384 - acc: 0.9893\n",
      "Epoch 821/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0391 - acc: 0.9891\n",
      "Epoch 822/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0394 - acc: 0.9892\n",
      "Epoch 823/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0383 - acc: 0.9895\n",
      "Epoch 824/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0390 - acc: 0.9891\n",
      "Epoch 825/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0387 - acc: 0.9892\n",
      "Epoch 826/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9893\n",
      "Epoch 827/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0387 - acc: 0.9893\n",
      "Epoch 828/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0397 - acc: 0.9888\n",
      "Epoch 829/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0386 - acc: 0.9893\n",
      "Epoch 830/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9890\n",
      "Epoch 831/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0390 - acc: 0.9892\n",
      "Epoch 832/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0391 - acc: 0.9891\n",
      "Epoch 833/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9895\n",
      "Epoch 834/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0389 - acc: 0.9892\n",
      "Epoch 835/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9891\n",
      "Epoch 836/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0380 - acc: 0.9894\n",
      "Epoch 837/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0387 - acc: 0.9894\n",
      "Epoch 838/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9895\n",
      "Epoch 839/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9894\n",
      "Epoch 840/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9893\n",
      "Epoch 841/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9894\n",
      "Epoch 842/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0388 - acc: 0.9891\n",
      "Epoch 843/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9895\n",
      "Epoch 844/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0386 - acc: 0.9893\n",
      "Epoch 845/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0391 - acc: 0.9891\n",
      "Epoch 846/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9891\n",
      "Epoch 847/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0386 - acc: 0.9893\n",
      "Epoch 848/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0390 - acc: 0.9892\n",
      "Epoch 849/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9896\n",
      "Epoch 850/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9895\n",
      "Epoch 851/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9895\n",
      "Epoch 852/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0384 - acc: 0.9894\n",
      "Epoch 853/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9892\n",
      "Epoch 854/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9894\n",
      "Epoch 855/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0378 - acc: 0.9894\n",
      "Epoch 856/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0378 - acc: 0.9896\n",
      "Epoch 857/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9895\n",
      "Epoch 858/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0384 - acc: 0.9895\n",
      "Epoch 859/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0380 - acc: 0.9896\n",
      "Epoch 860/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9895\n",
      "Epoch 861/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0389 - acc: 0.9894\n",
      "Epoch 862/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9895\n",
      "Epoch 863/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0384 - acc: 0.9894\n",
      "Epoch 864/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9894\n",
      "Epoch 865/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0384 - acc: 0.9894\n",
      "Epoch 866/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9895\n",
      "Epoch 867/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0378 - acc: 0.9896\n",
      "Epoch 868/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9894\n",
      "Epoch 869/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9896\n",
      "Epoch 870/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0389 - acc: 0.9893\n",
      "Epoch 871/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0390 - acc: 0.9893\n",
      "Epoch 872/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0393 - acc: 0.9893\n",
      "Epoch 873/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9896\n",
      "Epoch 874/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9897\n",
      "Epoch 875/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0377 - acc: 0.9895\n",
      "Epoch 876/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9894\n",
      "Epoch 877/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9895\n",
      "Epoch 878/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9896\n",
      "Epoch 879/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0391 - acc: 0.9894\n",
      "Epoch 880/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0385 - acc: 0.9895\n",
      "Epoch 881/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9895\n",
      "Epoch 882/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9896\n",
      "Epoch 883/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9897\n",
      "Epoch 884/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0387 - acc: 0.9895\n",
      "Epoch 885/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9895\n",
      "Epoch 886/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0386 - acc: 0.9894\n",
      "Epoch 887/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0391 - acc: 0.9892\n",
      "Epoch 888/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0387 - acc: 0.9894\n",
      "Epoch 889/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9896\n",
      "Epoch 890/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9897\n",
      "Epoch 891/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0389 - acc: 0.9894\n",
      "Epoch 892/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0378 - acc: 0.9898\n",
      "Epoch 893/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9895\n",
      "Epoch 894/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0384 - acc: 0.9895\n",
      "Epoch 895/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0373 - acc: 0.9898\n",
      "Epoch 896/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0381 - acc: 0.9896\n",
      "Epoch 897/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9897\n",
      "Epoch 898/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9897\n",
      "Epoch 899/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0392 - acc: 0.9894\n",
      "Epoch 900/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9897\n",
      "Epoch 901/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9895\n",
      "Epoch 902/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0384 - acc: 0.9895\n",
      "Epoch 903/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0384 - acc: 0.9896\n",
      "Epoch 904/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0375 - acc: 0.9897\n",
      "Epoch 905/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9897\n",
      "Epoch 906/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9896\n",
      "Epoch 907/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9896\n",
      "Epoch 908/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0373 - acc: 0.9899\n",
      "Epoch 909/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0364 - acc: 0.9900\n",
      "Epoch 910/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0379 - acc: 0.9897\n",
      "Epoch 911/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0383 - acc: 0.9895\n",
      "Epoch 912/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0379 - acc: 0.9896\n",
      "Epoch 913/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0385 - acc: 0.9897\n",
      "Epoch 914/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0371 - acc: 0.9900\n",
      "Epoch 915/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0387 - acc: 0.9894\n",
      "Epoch 916/1000\n",
      "29401/29401 [==============================] - 0s 16us/step - loss: 0.0383 - acc: 0.9897\n",
      "Epoch 917/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0376 - acc: 0.9897\n",
      "Epoch 918/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0369 - acc: 0.9900\n",
      "Epoch 919/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0381 - acc: 0.9897\n",
      "Epoch 920/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0372 - acc: 0.9900\n",
      "Epoch 921/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0383 - acc: 0.9895\n",
      "Epoch 922/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0374 - acc: 0.9899\n",
      "Epoch 923/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0376 - acc: 0.9897\n",
      "Epoch 924/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0374 - acc: 0.9899\n",
      "Epoch 925/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0377 - acc: 0.9897\n",
      "Epoch 926/1000\n",
      "29401/29401 [==============================] - 0s 16us/step - loss: 0.0378 - acc: 0.9897\n",
      "Epoch 927/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0381 - acc: 0.9897\n",
      "Epoch 928/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0374 - acc: 0.9899\n",
      "Epoch 929/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0375 - acc: 0.9899\n",
      "Epoch 930/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0368 - acc: 0.9900\n",
      "Epoch 931/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0378 - acc: 0.9898\n",
      "Epoch 932/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0370 - acc: 0.9900\n",
      "Epoch 933/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0379 - acc: 0.9897\n",
      "Epoch 934/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0370 - acc: 0.9899\n",
      "Epoch 935/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0368 - acc: 0.9902\n",
      "Epoch 936/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0378 - acc: 0.9898\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0374 - acc: 0.9900\n",
      "Epoch 938/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0382 - acc: 0.9897\n",
      "Epoch 939/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9898\n",
      "Epoch 940/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0375 - acc: 0.9899\n",
      "Epoch 941/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9898\n",
      "Epoch 942/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0378 - acc: 0.9898\n",
      "Epoch 943/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0381 - acc: 0.9898\n",
      "Epoch 944/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9899\n",
      "Epoch 945/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0375 - acc: 0.9898\n",
      "Epoch 946/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9896\n",
      "Epoch 947/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0380 - acc: 0.9897\n",
      "Epoch 948/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0374 - acc: 0.9899\n",
      "Epoch 949/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0374 - acc: 0.9900\n",
      "Epoch 950/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0368 - acc: 0.9902\n",
      "Epoch 951/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9899\n",
      "Epoch 952/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0377 - acc: 0.9900\n",
      "Epoch 953/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0372 - acc: 0.9900\n",
      "Epoch 954/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0370 - acc: 0.9899\n",
      "Epoch 955/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9898\n",
      "Epoch 956/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0371 - acc: 0.9900\n",
      "Epoch 957/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0369 - acc: 0.9900\n",
      "Epoch 958/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0364 - acc: 0.9903\n",
      "Epoch 959/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0380 - acc: 0.9898\n",
      "Epoch 960/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0371 - acc: 0.9900\n",
      "Epoch 961/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0374 - acc: 0.9900\n",
      "Epoch 962/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0373 - acc: 0.9900\n",
      "Epoch 963/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0374 - acc: 0.9899\n",
      "Epoch 964/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0372 - acc: 0.9901\n",
      "Epoch 965/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0358 - acc: 0.9904\n",
      "Epoch 966/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0375 - acc: 0.9899\n",
      "Epoch 967/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0372 - acc: 0.9902\n",
      "Epoch 968/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0367 - acc: 0.9901\n",
      "Epoch 969/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0383 - acc: 0.9898\n",
      "Epoch 970/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0374 - acc: 0.9900\n",
      "Epoch 971/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0371 - acc: 0.9901\n",
      "Epoch 972/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0367 - acc: 0.9902\n",
      "Epoch 973/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0371 - acc: 0.9900\n",
      "Epoch 974/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0370 - acc: 0.9901\n",
      "Epoch 975/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0375 - acc: 0.9898\n",
      "Epoch 976/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0377 - acc: 0.9900\n",
      "Epoch 977/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0362 - acc: 0.9903\n",
      "Epoch 978/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0372 - acc: 0.9900\n",
      "Epoch 979/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0363 - acc: 0.9902\n",
      "Epoch 980/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0373 - acc: 0.9901\n",
      "Epoch 981/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0379 - acc: 0.9899\n",
      "Epoch 982/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0371 - acc: 0.9901\n",
      "Epoch 983/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0366 - acc: 0.9902\n",
      "Epoch 984/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0367 - acc: 0.9902\n",
      "Epoch 985/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0368 - acc: 0.9901\n",
      "Epoch 986/1000\n",
      "29401/29401 [==============================] - 0s 14us/step - loss: 0.0364 - acc: 0.9901\n",
      "Epoch 987/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0370 - acc: 0.9899\n",
      "Epoch 988/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0371 - acc: 0.9901\n",
      "Epoch 989/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0363 - acc: 0.9904\n",
      "Epoch 990/1000\n",
      "29401/29401 [==============================] - 0s 15us/step - loss: 0.0372 - acc: 0.9901\n",
      "Epoch 991/1000\n",
      "29401/29401 [==============================] - 0s 13us/step - loss: 0.0367 - acc: 0.9903\n",
      "Epoch 992/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0364 - acc: 0.9903\n",
      "Epoch 993/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0370 - acc: 0.9902\n",
      "Epoch 994/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0364 - acc: 0.9902\n",
      "Epoch 995/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0373 - acc: 0.9900\n",
      "Epoch 996/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0370 - acc: 0.9901\n",
      "Epoch 997/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0365 - acc: 0.9902\n",
      "Epoch 998/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0370 - acc: 0.9901\n",
      "Epoch 999/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0367 - acc: 0.9902\n",
      "Epoch 1000/1000\n",
      "29401/29401 [==============================] - 0s 12us/step - loss: 0.0372 - acc: 0.9900\n",
      "3267/3267 [==============================] - 0s 12us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCHES)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "We are now using the samples that we kept back to evaulate how well our model has learned to approximate the identity function. First, we define some \"pretty printing\" options, then we let our model make predictions and compare the evaluation samples with the outputs of the prediction, digit by digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVEN\n",
      "\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 50312\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 30040\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 49972\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 61866\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 3512\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 11988\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 25058\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 47692\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 51042\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 17118\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 10932\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 21106\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 55104\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 53264\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 15854\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 24010\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 25228\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 39754\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 20670\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 7670\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 20972\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 34576\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 13896\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 59606\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 57278\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 16950\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 46500\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 43916\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 21676\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 43580\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 62878\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 7120\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 41204\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 37694\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 42794\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 12056\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 14588\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 15068\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 43846\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 43312\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 63978\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 12240\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 44156\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 39238\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 9532\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 10800\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 52398\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 29192\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 46838\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 40324\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 148\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 48204\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 13508\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 42868\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 55366\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 1568\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 3054\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 34836\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 23686\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 63598\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 24472\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 50076\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 35274\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 39804\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 60534\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 980\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 37782\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 19764\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 16432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 16618\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 19318\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 64824\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 16570\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 44294\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 48784\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 41674\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 32836\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 38816\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 44152\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 28422\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 51282\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 53536\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 4370\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 38162\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 8126\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 36638\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 14772\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 37250\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 64028\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 54138\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 25038\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 17306\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 39234\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 64238\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 39926\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 18564\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m 9494\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 41588\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 33388\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m 58568\n",
      "\n",
      "ODD\n",
      "\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 59436\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 51576\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 42680\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 1970\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 27796\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 2310\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 55526\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 58380\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 26876\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 23980\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 49808\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 38398\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 51970\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 29790\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 18982\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 3500\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 35994\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 59480\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 30386\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 54246\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 2770\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 27610\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 56304\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 57786\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 10954\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 60066\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 31922\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 46376\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 5386\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 10828\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 16702\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 61880\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 1640\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 47848\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 21888\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 59108\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 35012\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 50844\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 30894\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 25640\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 28326\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 47382\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 36100\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 60806\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 54704\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 25604\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 54974\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 50978\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 14562\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 18782\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 23226\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 11544\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 330\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 45222\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 63370\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 35174\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 29010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 54470\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 16588\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 19022\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 14134\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 13976\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 33122\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 18000\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 25982\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 40256\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 63860\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 594\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 36480\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 38808\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 42944\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 57108\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 52904\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 48710\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 26714\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 30632\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 2404\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 57038\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 28112\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 30422\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 22350\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 17618\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 30108\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 38706\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 7234\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 48434\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 21838\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 11384\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 32488\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 13728\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 33882\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 74\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 38024\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 27778\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 1338\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 31482\n",
      "\u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 6174\n",
      "\u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[91m0\u001b[0m 36164\n",
      "\u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 30702\n",
      "\u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[92m1\u001b[0m \u001b[92m0\u001b[0m \u001b[92m0\u001b[0m \u001b[92m1\u001b[0m \u001b[91m0\u001b[0m 64178\n"
     ]
    }
   ],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "x_pred_even = np.rint(model.predict(x_val_even)).astype(np.uint8)\n",
    "x_pred_odd = np.rint(model.predict(x_val_odd)).astype(np.uint8)\n",
    "\n",
    "print('EVEN\\n')\n",
    "for y in range(VAL):\n",
    "    for x in range(BITS):\n",
    "        if f(x_val_even)[y, x] == x_pred_even[y, x]:\n",
    "            print(colors.ok + str(x_pred_even[y, x]) + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + str(x_pred_even[y, x]) + colors.close, end=' ')\n",
    "    # https://stackoverflow.com/questions/41069825/convert-binary-01-numpy-to-integer-or-binary-string#41069967\n",
    "    print(x_pred_even[y,:].dot(2**np.arange(x_pred_even[y,:].size)[::-1]))\n",
    "\n",
    "print('\\nODD\\n')\n",
    "for y in range(VAL):\n",
    "    for x in range(BITS):\n",
    "        if f(x_val_odd)[y, x] == x_pred_odd[y, x]:\n",
    "            print(colors.ok + str(x_pred_odd[y, x]) + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + str(x_pred_odd[y, x]) + colors.close, end=' ')\n",
    "    # https://stackoverflow.com/questions/41069825/convert-binary-01-numpy-to-integer-or-binary-string#41069967\n",
    "    print(x_pred_odd[y,:].dot(2**np.arange(x_pred_odd[y,:].size)[::-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "- Agre, Philip E. *Computation and Human Experience*. Cambridge University Press, 1997.\n",
    "- Agre, Philip E. \"The Soul Gained and Lost. Artificial Intelligence as a Philosophical Project.\" Stanford Humanities Review 4, no. 2 (1995): 1–19.\n",
    "- Hornik, Kurt, Maxwell Stinchcombe, and Halbert White. \"Multilayer Feedforward Networks Are Universal Approximators.\" Neural Networks 2, no. 5 (1989): 359–66.\n",
    "- Lake, Brenden M., Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman. \"Building Machines That Learn and Think Like People.\" Behavioral and Brain Sciences 40 (2017).\n",
    "- Marcus, Gary. \"Deep Learning: A Critical Appraisal.\" arXiv Preprint arXiv:1801.00631, 2018. https://arxiv.org/abs/1801.00631v1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
